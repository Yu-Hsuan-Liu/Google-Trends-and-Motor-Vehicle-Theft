{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tosea\\AppData\\Local\\Temp\\ipykernel_30480\\653851449.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import datetime\n",
    "import csv\n",
    "global driver\n",
    "import bash\n",
    "from selenium.webdriver.common.by import By\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from faker import Faker\n",
    "import shutil\n",
    "import os\n",
    "import secrets\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "fake = Faker('zh_TW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    #https://pypi.org/project/torpy/\n",
    "    #pip install torpy\n",
    "    from torpy import TorClient\n",
    "    hostname = 'ifconfig.me'  # It's possible use onion hostname here as well\n",
    "    with TorClient() as tor:\n",
    "        # Choose random guard node and create 3-hops circuit\n",
    "        with tor.create_circuit(3) as circuit:\n",
    "            # Create tor stream to host\n",
    "            with circuit.create_stream((hostname, 80)) as stream:\n",
    "                # Now we can communicate with host\n",
    "                stream.send(b'GET / HTTP/1.0\\r\\nHost: %s\\r\\n\\r\\n' % hostname.encode())\n",
    "                recv = stream.recv(1024)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate start and end dates for each month\n",
    "def generate_monthly_dates(start_year, end_year):\n",
    "    dates = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            # Find the number of days in the month\n",
    "            days_in_month = calendar.monthrange(year, month)[1]\n",
    "            # Generate start and end dates\n",
    "            start_date = datetime(year, month, 1).strftime(\"%m/%d/%Y\")\n",
    "            end_date = datetime(year, month, days_in_month).strftime(\"%m/%d/%Y\")\n",
    "            dates.append((start_date, end_date))\n",
    "    return dates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('09/26/2022', '10/02/2022')\n",
      "('10/03/2022', '10/09/2022')\n",
      "('10/10/2022', '10/16/2022')\n",
      "('10/17/2022', '10/23/2022')\n",
      "('10/24/2022', '10/30/2022')\n",
      "('10/31/2022', '11/06/2022')\n",
      "('11/07/2022', '11/13/2022')\n",
      "('11/14/2022', '11/20/2022')\n",
      "('11/21/2022', '11/27/2022')\n",
      "('11/28/2022', '12/04/2022')\n",
      "('12/05/2022', '12/11/2022')\n",
      "('12/12/2022', '12/18/2022')\n",
      "('12/19/2022', '12/25/2022')\n",
      "('12/26/2022', '12/31/2022')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_weekly_dates(start_date_str, end_date_str):\n",
    "    # Convert input strings to datetime objects\n",
    "    start_date = datetime.strptime(start_date_str, \"%m/%d/%Y\")\n",
    "    end_date = datetime.strptime(end_date_str, \"%m/%d/%Y\")\n",
    "    \n",
    "    dates = []\n",
    "    # Iterate through each week\n",
    "    while start_date <= end_date:\n",
    "        # Get the end of the week\n",
    "        end_of_week = start_date + timedelta(days=(6 - start_date.weekday()))\n",
    "        # Ensure the end of the week does not exceed the end date\n",
    "        if end_of_week > end_date:\n",
    "            end_of_week = end_date\n",
    "        # Append the start and end of the week to the list\n",
    "        dates.append((start_date.strftime(\"%m/%d/%Y\"), end_of_week.strftime(\"%m/%d/%Y\")))\n",
    "        # Move to the start of the next week\n",
    "        start_date = end_of_week + timedelta(days=1)\n",
    "    \n",
    "    return dates\n",
    "\n",
    "# Example usage:\n",
    "start_date = \"09/26/2022\"\n",
    "end_date = \"12/31/2022\"\n",
    "weekly_dates = generate_weekly_dates(start_date, end_date)\n",
    "for date_range in weekly_dates:\n",
    "    print(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('09/26/2022', '10/02/2022'),\n",
       " ('10/03/2022', '10/09/2022'),\n",
       " ('10/10/2022', '10/16/2022'),\n",
       " ('10/17/2022', '10/23/2022'),\n",
       " ('10/24/2022', '10/30/2022'),\n",
       " ('10/31/2022', '11/06/2022'),\n",
       " ('11/07/2022', '11/13/2022'),\n",
       " ('11/14/2022', '11/20/2022'),\n",
       " ('11/21/2022', '11/27/2022'),\n",
       " ('11/28/2022', '12/04/2022'),\n",
       " ('12/05/2022', '12/11/2022'),\n",
       " ('12/12/2022', '12/18/2022'),\n",
       " ('12/19/2022', '12/25/2022'),\n",
       " ('12/26/2022', '12/31/2022')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registration\n",
    "def get_data(duration):\n",
    "    #init()\n",
    "    #open chrome in incognito mode\n",
    "    #init()\n",
    "    options = webdriver.EdgeOptions()\n",
    "    edge_driver_path = r'msedgedriver.exe'\n",
    "\n",
    "# Create a WebDriver instance for Microsoft Edge\n",
    "    \n",
    "    if duration == \"week\":\n",
    "    # Generate monthly dates from 2017 to 2023\n",
    "        duration_dates = generate_weekly_dates(\"12/27/2021\", \"12/31/2021\")\n",
    "    elif duration == \"month\":\n",
    "        generate_weekly_dates(2017, 2023)\n",
    "\n",
    "    # Print the list of start and end dates for each month\n",
    "    for date_range in duration_dates:\n",
    "        start_date = date_range[0] \n",
    "        end_date = date_range[1]\n",
    "        driver = webdriver.Edge(options = options, executable_path=edge_driver_path)   \n",
    "        driver.get(\"https://webapp3.sanantonio.gov/policecalls/Reports.aspx\")\n",
    "        time.sleep(random.randint(5, 10))\n",
    "        print( start_date, \"-\", end_date)\n",
    "        driver.find_element(\"xpath\", \"/html/body/form/div[3]/table/tbody/tr[4]/td[2]/input\").send_keys(start_date)\n",
    "        time.sleep(random.randint(1, 4))\n",
    "        driver.find_element(\"xpath\", \"/html/body/form/div[3]/table/tbody/tr[5]/td[2]/table/tbody/tr/td[2]/input\").send_keys(duration)\n",
    "        time.sleep(random.randint(1, 4))\n",
    "        driver.find_element(\"xpath\", \"/html/body/form/div[3]/table/tbody/tr[5]/td[2]/input\").send_keys(end_date)\n",
    "        time.sleep(random.randint(1, 4))\n",
    "        select_ed = Select(driver.find_element(\"xpath\",'/html/body/form/div[3]/table/tbody/tr[8]/td[2]/select'))\n",
    "        select_ed.select_by_value(\"Property Crime Calls\")\n",
    "        driver.find_element(\"xpath\", \"/html/body/form/div[3]/table/tbody/tr[13]/td/input[1]\").click()\n",
    "        time.sleep(random.randint(10, 12))\n",
    "\n",
    "        table = driver.find_element(\"xpath\", \"/html/body/form/div[3]/table/tbody/tr/td/div/table\")\n",
    "        with open(f\"sanantonio_911_{start_date.replace('/', '')}_{end_date.replace('/', '')}.csv\", 'w', newline='') as csvfile:\n",
    "            wr = csv.writer(csvfile)\n",
    "            for row in table.find_elements(\"css selector\",'tr'):\n",
    "                wr.writerow([d.text for d in row.find_elements(\"css selector\",'td')])\n",
    "         # Close the browser\n",
    "        time.sleep(random.randint(5, 8))\n",
    "        driver.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tosea\\AppData\\Local\\Temp\\ipykernel_30480\\4228362399.py:21: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge(options = options, executable_path=edge_driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/27/2021 - 12/31/2021\n"
     ]
    }
   ],
   "source": [
    "get_data(\"week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "missed dates\n",
    "\n",
    "12/31/2018\n",
    "12/30/2019 - 12/31/2019\n",
    "12/28/2020 - 12/31/2020\n",
    "12/27/2021 - 12/31/2021\n",
    "\n",
    "# 3/4/2024 \n",
    "Checked for the denormalizing method proposed by Shahan A. Memon\n",
    "file:///C:/Users/tosea/Downloads/jmir_v22i1e13347_app2.pdf\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7011125/\n",
    "\n",
    "However, this method does not working for the following reasons\n",
    "1. Becasue not every DMA will show up on the map, it did not consider zero values in every sample\n",
    "2. When it comes to month, usually we will see a please have a very high variation\n",
    "in 100 comparing to all other DMAs (usually 100: 14: 10 :11 : 9), which means in that month, one area has extremely high search than the others.\n",
    "I am not sure how to interpret this. more study or research may be needed. For now, I will just continue with my plan: comparing\n",
    "GT data without de-normalize them.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the column names\n",
    "column_names = [\"INCIDENT NUMBER\", \"CATEGORY\", \"PROBLEM TYPE\", \"RESPONSE DATE\", \"ADDRESS\", \"HOA\", \"SCHOOL DISTRICT\", \"COUNCIL DISTRICT\", \"ZIPCODE\"]\n",
    "\n",
    "# Path to the directory containing CSV files\n",
    "directory = r\"C:\\Users\\tosea\\Liu_Dissertation_GT_Code\\sanantonio_911_files\"\n",
    "\n",
    "# Initialize an empty list to store data frames\n",
    "dfs = []\n",
    "\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Read the CSV file without header\n",
    "        df = pd.read_csv(os.path.join(directory, filename), header=None, encoding='ISO-8859-1')\n",
    "        # Add column names\n",
    "        df.columns = column_names\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrame to a new CSV file\n",
    "concatenated_df.to_csv('san_antonio_cfs.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
